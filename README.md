# GoalGetter

An educational app with an AI-Tutor

## How it works

- Goal
  At the onboarding the user states what he wants to learn, and answers some follow-up questions
- Objective
  The next immediate step towards the goal
  Once the student shows they dominate the objective, we create a new one
- Lessons
  Multiple Choice questions with didatic purpose
  Subjective questions to stimulate thinking
  Subjective questions aiming at assessing the student's knowledge
- Tutoring
  A chatbot with knowledge about the user
- Gamefication
  Leaderboards
  Missions
  Achievments
- Resources
  Recommendations of Websites, Youtube Channels and eBooks

All content is custom-tailored for the user. It's a 1:1 Tutor App!

## Philosophy

- Goal
  Must be the most ambitious possible
- Small steps
  Each objective is the smallest step possible above the student's current level
- Gamification
  We have XP and Streaks, aimed at user-retention
- 1:1 Tutoring
  We record data and context all the time. That is used to create a custom-tailored experience

## Tech Stack and Infrastructure

Flutter: - Webapp and Android
FastApi / Pytest
Client_SDK: - Generated by OpenApi code-generator, using swagger-ui's openapi.json
Terraform Cloudflare setup

We use Google Gemini-3-Flash and Ollama

# How to run

Install [Ollama](https://ollama.com/download). I presume you have the GPU drivers.
If you own and AMD GPU you're in for a bad time.

You will need a Gemini API Key. You can get it in a free tier at [Google AI Studio](https://aistudio.google.com/api-keys). GCP account is probably required.

Copy example.env into a .env and replace the API key.

`docker-compose up -d`

You can stop the backend and frontend instances then.
I trust you'll stop the Cloudflare Tunnel image and not steal my life's work.

To start the:
backend: `uvicorn backend.main:app --reload`
frontend: `flutter run -d chrome --web-port=8080`

Whenever you change the api, you can get the .json specs at [swagger-ui](http://127.0.0.1:8000/openapi.docs)

Then generate the Client_sdk with:
`openapi-generator-cli generate -i ./openapi.json -g dart -o ./client_sdk`

_The web version is meant for the MVP. This app is meant as a mobile app only_

# Infra

_This is a rabbit hole_

Gemini for Onboarding, which isn't done frequently
Gemini for embedding
Ollama Cloud for for running cloud models and fallback to local when quota is exceeded
Re-use other people's content to save on generation

Cloudflare Tunnel to reverse proxy so we can home-deploy
Cloudflare R2 to backup the SQL

# Note

Gemini does not support pydantic's Field annotators

# Future notes

We have to make a fallback so, if we exceed the Ollama-Cloud Quota:
we either

- Wait for the next hour
- Fallback to local

Depends on what you're doing:

- Content generation can wait (lessons, objective notes, achievments, resources)
- Others can not (Chatbot, Objective)
